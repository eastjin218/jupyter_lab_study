{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "LearningPySpark_Chapter05.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eastjin218/jupyter_lab_study/blob/master/LearningPySpark_Chapter05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyPw93NWGtZM",
        "colab_type": "text"
      },
      "source": [
        "# Introducing MLib package of PySpark "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxF1o_nAGtZP",
        "colab_type": "text"
      },
      "source": [
        "## Load and transform the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvVFY76SGtZR",
        "colab_type": "text"
      },
      "source": [
        "Just like in the previous chapter, we first specify the schema of our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFRbbD5FHJOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGX7x3fYI8JL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://apache.tt.co.kr/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVE_EjNhI8QJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xzvf spark-2.4.5-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8XnwiGpOBD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVHIh-bZGtZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark, pyspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "conf = pyspark.SparkConf().setAppName('appName').setMaster('local')\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession(sc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIc-paK1NoDX",
        "colab_type": "code",
        "outputId": "800addcc-f952-447c-ae6f-dd885096d8b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebtbXJxNGtZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyspark.sql.types as typ\n",
        "\n",
        "labels = [\n",
        "    ('INFANT_ALIVE_AT_REPORT', typ.StringType()),\n",
        "    ('BIRTH_YEAR', typ.IntegerType()),\n",
        "    ('BIRTH_MONTH', typ.IntegerType()),\n",
        "    ('BIRTH_PLACE', typ.StringType()),\n",
        "    ('MOTHER_AGE_YEARS', typ.IntegerType()),\n",
        "    ('MOTHER_RACE_6CODE', typ.StringType()),\n",
        "    ('MOTHER_EDUCATION', typ.StringType()),\n",
        "    ('FATHER_COMBINED_AGE', typ.IntegerType()),\n",
        "    ('FATHER_EDUCATION', typ.StringType()),\n",
        "    ('MONTH_PRECARE_RECODE', typ.StringType()),\n",
        "    ('CIG_BEFORE', typ.IntegerType()),\n",
        "    ('CIG_1_TRI', typ.IntegerType()),\n",
        "    ('CIG_2_TRI', typ.IntegerType()),\n",
        "    ('CIG_3_TRI', typ.IntegerType()),\n",
        "    ('MOTHER_HEIGHT_IN', typ.IntegerType()),\n",
        "    ('MOTHER_BMI_RECODE', typ.IntegerType()),\n",
        "    ('MOTHER_PRE_WEIGHT', typ.IntegerType()),\n",
        "    ('MOTHER_DELIVERY_WEIGHT', typ.IntegerType()),\n",
        "    ('MOTHER_WEIGHT_GAIN', typ.IntegerType()),\n",
        "    ('DIABETES_PRE', typ.StringType()),\n",
        "    ('DIABETES_GEST', typ.StringType()),\n",
        "    ('HYP_TENS_PRE', typ.StringType()),\n",
        "    ('HYP_TENS_GEST', typ.StringType()),\n",
        "    ('PREV_BIRTH_PRETERM', typ.StringType()),\n",
        "    ('NO_RISK', typ.StringType()),\n",
        "    ('NO_INFECTIONS_REPORTED', typ.StringType()),\n",
        "    ('LABOR_IND', typ.StringType()),\n",
        "    ('LABOR_AUGM', typ.StringType()),\n",
        "    ('STEROIDS', typ.StringType()),\n",
        "    ('ANTIBIOTICS', typ.StringType()),\n",
        "    ('ANESTHESIA', typ.StringType()),\n",
        "    ('DELIV_METHOD_RECODE_COMB', typ.StringType()),\n",
        "    ('ATTENDANT_BIRTH', typ.StringType()),\n",
        "    ('APGAR_5', typ.IntegerType()),\n",
        "    ('APGAR_5_RECODE', typ.StringType()),\n",
        "    ('APGAR_10', typ.IntegerType()),\n",
        "    ('APGAR_10_RECODE', typ.StringType()),\n",
        "    ('INFANT_SEX', typ.StringType()),\n",
        "    ('OBSTETRIC_GESTATION_WEEKS', typ.IntegerType()),\n",
        "    ('INFANT_WEIGHT_GRAMS', typ.IntegerType()),\n",
        "    ('INFANT_ASSIST_VENTI', typ.StringType()),\n",
        "    ('INFANT_ASSIST_VENTI_6HRS', typ.StringType()),\n",
        "    ('INFANT_NICU_ADMISSION', typ.StringType()),\n",
        "    ('INFANT_SURFACANT', typ.StringType()),\n",
        "    ('INFANT_ANTIBIOTICS', typ.StringType()),\n",
        "    ('INFANT_SEIZURES', typ.StringType()),\n",
        "    ('INFANT_NO_ABNORMALITIES', typ.StringType()),\n",
        "    ('INFANT_ANCEPHALY', typ.StringType()),\n",
        "    ('INFANT_MENINGOMYELOCELE', typ.StringType()),\n",
        "    ('INFANT_LIMB_REDUCTION', typ.StringType()),\n",
        "    ('INFANT_DOWN_SYNDROME', typ.StringType()),\n",
        "    ('INFANT_SUSPECTED_CHROMOSOMAL_DISORDER', typ.StringType()),\n",
        "    ('INFANT_NO_CONGENITAL_ANOMALIES_CHECKED', typ.StringType()),\n",
        "    ('INFANT_BREASTFED', typ.StringType())\n",
        "]\n",
        "\n",
        "schema = typ.StructType([\n",
        "        typ.StructField(e[0], e[1], False) for e in labels\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w5Wg6m7GtZY",
        "colab_type": "text"
      },
      "source": [
        "Next, we load the data.\n",
        "\n",
        "http://www.domdrabas.com/data/LearningPySpark/births_train.csv.gz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "rqiVFHyPGtZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "births = spark.read.csv('births_train.csv.gz', \n",
        "                        header=True, \n",
        "                        schema=schema)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSyn7YgzGtZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(births)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvTqKpk-GtZg",
        "colab_type": "text"
      },
      "source": [
        "Specify our recode dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm4fdeDXGtZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "recode_dictionary = {\n",
        "    'YNU': {\n",
        "        'Y': 1,\n",
        "        'N': 0,\n",
        "        'U': 0\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gUZIgEEGtZk",
        "colab_type": "text"
      },
      "source": [
        "Our goal is to predict whether the `'INFANT_ALIVE_AT_REPORT'` is either 1 or 0. Thus, we will drop all of the features that relate to the infant."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Mn6K1qMPGtZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "selected_features = [\n",
        "    'INFANT_ALIVE_AT_REPORT', \n",
        "    'BIRTH_PLACE', \n",
        "    'MOTHER_AGE_YEARS', \n",
        "    'FATHER_COMBINED_AGE', \n",
        "    'CIG_BEFORE', \n",
        "    'CIG_1_TRI', \n",
        "    'CIG_2_TRI', \n",
        "    'CIG_3_TRI', \n",
        "    'MOTHER_HEIGHT_IN', \n",
        "    'MOTHER_PRE_WEIGHT', \n",
        "    'MOTHER_DELIVERY_WEIGHT', \n",
        "    'MOTHER_WEIGHT_GAIN', \n",
        "    'DIABETES_PRE', \n",
        "    'DIABETES_GEST', \n",
        "    'HYP_TENS_PRE', \n",
        "    'HYP_TENS_GEST', \n",
        "    'PREV_BIRTH_PRETERM'\n",
        "]\n",
        "\n",
        "births_trimmed = births.select(selected_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEJrH9hrGtZn",
        "colab_type": "code",
        "outputId": "9c3f2856-1097-4611-fa38-793b7a2799e4",
        "colab": {}
      },
      "source": [
        "births_trimmed.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(INFANT_ALIVE_AT_REPORT='N', BIRTH_PLACE='1', MOTHER_AGE_YEARS=29, FATHER_COMBINED_AGE=99, CIG_BEFORE=99, CIG_1_TRI=99, CIG_2_TRI=99, CIG_3_TRI=99, MOTHER_HEIGHT_IN=99, MOTHER_PRE_WEIGHT=999, MOTHER_DELIVERY_WEIGHT=999, MOTHER_WEIGHT_GAIN=99, DIABETES_PRE='N', DIABETES_GEST='N', HYP_TENS_PRE='N', HYP_TENS_GEST='N', PREV_BIRTH_PRETERM='N')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnHfMOwyGtZp",
        "colab_type": "text"
      },
      "source": [
        "Specify the recoding methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz6gvFUWGtZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyspark.sql.functions as func\n",
        "\n",
        "def recode(col, key):        \n",
        "    return recode_dictionary[key][col] \n",
        "\n",
        "def correct_cig(feat):\n",
        "    return func \\\n",
        "        .when(func.col(feat) != 99, func.col(feat))\\\n",
        "        .otherwise(0)\n",
        "\n",
        "rec_integer = func.udf(recode, typ.IntegerType())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPd6rFY0GtZt",
        "colab_type": "text"
      },
      "source": [
        "Correct the features related to the number of smoked cigarettes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53cNjtd4GtZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "births_transformed = births_trimmed \\\n",
        "    .withColumn('CIG_BEFORE', correct_cig('CIG_BEFORE'))\\\n",
        "    .withColumn('CIG_1_TRI', correct_cig('CIG_1_TRI'))\\\n",
        "    .withColumn('CIG_2_TRI', correct_cig('CIG_2_TRI'))\\\n",
        "    .withColumn('CIG_3_TRI', correct_cig('CIG_3_TRI'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL-igkoUGtZw",
        "colab_type": "text"
      },
      "source": [
        "Figure out which Yes/No/Unknown features are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O8Z2HNNGtZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = [(col.name, col.dataType) for col in births_trimmed.schema]\n",
        "\n",
        "YNU_cols = []\n",
        "\n",
        "for i, s in enumerate(cols):\n",
        "    if s[1] == typ.StringType():\n",
        "        dis = births.select(s[0]) \\\n",
        "            .distinct() \\\n",
        "            .rdd \\\n",
        "            .map(lambda row: row[0]) \\\n",
        "            .collect()\n",
        "\n",
        "        if 'Y' in dis:\n",
        "            YNU_cols.append(s[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbmQzHo3GtZz",
        "colab_type": "text"
      },
      "source": [
        "DataFrames can transform the features *in bulk* while selecting features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "6cc7cliQGtZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "births.select([\n",
        "        'INFANT_NICU_ADMISSION', \n",
        "        rec_integer(\n",
        "            'INFANT_NICU_ADMISSION', func.lit('YNU')\n",
        "        ) \\\n",
        "        .alias('INFANT_NICU_ADMISSION_RECODE')]\n",
        "     ).take(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW9V_9p-GtZ2",
        "colab_type": "text"
      },
      "source": [
        "Transform all the `YNU_cols` in one using a list of transformations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Qi1IZ8NGtZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exprs_YNU = [\n",
        "    rec_integer(x, func.lit('YNU')).alias(x) \n",
        "    if x in YNU_cols \n",
        "    else x \n",
        "    for x in births_transformed.columns\n",
        "]\n",
        "\n",
        "births_transformed = births_transformed.select(exprs_YNU)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7AZsrZVGtZ5",
        "colab_type": "text"
      },
      "source": [
        "Let's check if we got it correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "zeHWD5tiGtZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "births_transformed.select(YNU_cols[-5:]).show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80t-YW37GtZ8",
        "colab_type": "text"
      },
      "source": [
        "## Get to know your data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDXt4_T7GtZ9",
        "colab_type": "text"
      },
      "source": [
        "### Descriptive statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoMWRWJyGtZ-",
        "colab_type": "text"
      },
      "source": [
        "We will use the `colStats(...)` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "2cnTEA7HGtZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyspark.mllib.stat as st\n",
        "import numpy as np\n",
        "\n",
        "numeric_cols = ['MOTHER_AGE_YEARS','FATHER_COMBINED_AGE',\n",
        "                'CIG_BEFORE','CIG_1_TRI','CIG_2_TRI','CIG_3_TRI',\n",
        "                'MOTHER_HEIGHT_IN','MOTHER_PRE_WEIGHT',\n",
        "                'MOTHER_DELIVERY_WEIGHT','MOTHER_WEIGHT_GAIN'\n",
        "               ]\n",
        "\n",
        "numeric_rdd = births_transformed\\\n",
        "                       .select(numeric_cols)\\\n",
        "                       .rdd \\\n",
        "                       .map(lambda row: [e for e in row])\n",
        "\n",
        "mllib_stats = st.Statistics.colStats(numeric_rdd)\n",
        "\n",
        "for col, m, v in zip(numeric_cols, \n",
        "                     mllib_stats.mean(), \n",
        "                     mllib_stats.variance()):\n",
        "    print('{0}: \\t{1:.2f} \\t {2:.2f}'.format(col, m, np.sqrt(v)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWITYeCZGtaA",
        "colab_type": "text"
      },
      "source": [
        "For the categorical variables we will calculate the frequencies of their values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "wAmHwxMIGtaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_cols = [e for e in births_transformed.columns \n",
        "                    if e not in numeric_cols]\n",
        "\n",
        "categorical_rdd = births_transformed\\\n",
        "                       .select(categorical_cols)\\\n",
        "                       .rdd \\\n",
        "                       .map(lambda row: [e for e in row])\n",
        "            \n",
        "for i, col in enumerate(categorical_cols):\n",
        "    agg = categorical_rdd \\\n",
        "        .groupBy(lambda row: row[i]) \\\n",
        "        .map(lambda row: (row[0], len(row[1])))\n",
        "        \n",
        "    print(col, sorted(agg.collect(), \n",
        "                      key=lambda el: el[1], \n",
        "                      reverse=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADmgPzkFGtaE",
        "colab_type": "text"
      },
      "source": [
        "### Correlations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wamRAh4qGtaF",
        "colab_type": "text"
      },
      "source": [
        "Correlations between our features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "icwG9bScGtaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corrs = st.Statistics.corr(numeric_rdd)\n",
        "\n",
        "for i, el in enumerate(corrs > 0.5):\n",
        "    correlated = [\n",
        "        (numeric_cols[j], corrs[i][j]) \n",
        "        for j, e in enumerate(el) \n",
        "        if e == 1.0 and j != i]\n",
        "    \n",
        "    if len(correlated) > 0:\n",
        "        for e in correlated:\n",
        "            print('{0}-to-{1}: {2:.2f}' \\\n",
        "                  .format(numeric_cols[i], e[0], e[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1MRKfdaGtaI",
        "colab_type": "text"
      },
      "source": [
        "We can drop most of highly correlated features. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "m8WEqADtGtaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_to_keep = [\n",
        "    'INFANT_ALIVE_AT_REPORT', \n",
        "    'BIRTH_PLACE', \n",
        "    'MOTHER_AGE_YEARS', \n",
        "    'FATHER_COMBINED_AGE', \n",
        "    'CIG_1_TRI', \n",
        "    'MOTHER_HEIGHT_IN', \n",
        "    'MOTHER_PRE_WEIGHT', \n",
        "    'DIABETES_PRE', \n",
        "    'DIABETES_GEST', \n",
        "    'HYP_TENS_PRE', \n",
        "    'HYP_TENS_GEST', \n",
        "    'PREV_BIRTH_PRETERM'\n",
        "]\n",
        "births_transformed = births_transformed.select([e for e in features_to_keep])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "010q5zwbGtaM",
        "colab_type": "text"
      },
      "source": [
        "### Statistical testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAk8cA4HGtaM",
        "colab_type": "text"
      },
      "source": [
        "Run a Chi-square test to determine if there are significant differences for categorical variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "pzgT4EFRGtaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyspark.mllib.linalg as ln\n",
        "\n",
        "for cat in categorical_cols[1:]:\n",
        "    agg = births_transformed \\\n",
        "        .groupby('INFANT_ALIVE_AT_REPORT') \\\n",
        "        .pivot(cat) \\\n",
        "        .count()    \n",
        "\n",
        "    agg_rdd = agg \\\n",
        "        .rdd\\\n",
        "        .map(lambda row: (row[1:])) \\\n",
        "        .flatMap(lambda row: \n",
        "                 [0 if e == None else e for e in row]) \\\n",
        "        .collect()\n",
        "\n",
        "    row_length = len(agg.collect()[0]) - 1\n",
        "    agg = ln.Matrices.dense(row_length, 2, agg_rdd)\n",
        "    \n",
        "    test = st.Statistics.chiSqTest(agg)\n",
        "    print(cat, round(test.pValue, 4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBZtp09CGtaP",
        "colab_type": "text"
      },
      "source": [
        "## Create the final dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_viCQV0XGtaQ",
        "colab_type": "text"
      },
      "source": [
        "### Create an RDD of `LabeledPoint`s\n",
        "\n",
        "We will use a hashing trick to encode the `'BIRTH_PLACE'` feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "BHwMpaRhGtaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyspark.mllib.feature as ft\n",
        "import pyspark.mllib.regression as reg\n",
        "\n",
        "hashing = ft.HashingTF(7)\n",
        "\n",
        "births_hashed = births_transformed \\\n",
        "    .rdd \\\n",
        "    .map(lambda row: [\n",
        "            list(hashing.transform(row[1]).toArray()) \n",
        "                if col == 'BIRTH_PLACE' \n",
        "                else row[i] \n",
        "            for i, col \n",
        "            in enumerate(features_to_keep)]) \\\n",
        "    .map(lambda row: [[e] if type(e) == int else e \n",
        "                      for e in row]) \\\n",
        "    .map(lambda row: [item for sublist in row \n",
        "                      for item in sublist]) \\\n",
        "    .map(lambda row: reg.LabeledPoint(\n",
        "            row[0], \n",
        "            ln.Vectors.dense(row[1:]))\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U3V23gOGtaT",
        "colab_type": "text"
      },
      "source": [
        "### Split into training and testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO5_NYeDGtaT",
        "colab_type": "text"
      },
      "source": [
        "Before we move to the modeling stage, we need to split our dataset into two sets: one we'll use for training and another one for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "HeZLXz_bGtaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "births_train, births_test = births_hashed.randomSplit([0.6, 0.4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6TfJLppGtaX",
        "colab_type": "text"
      },
      "source": [
        "## Predicting infant survival"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyTJHvjIGtaX",
        "colab_type": "text"
      },
      "source": [
        "### Logistic regression in Spark\n",
        "\n",
        "MLLib used to provide a logistic regression model estimated using a stochastic gradient descent (SGD) algorithm. This model has been deprecated in Spark 2.0 in favor of the `LogisticRegressionWithLBFGS` model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "batLWbNLGtaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.mllib.classification \\\n",
        "    import LogisticRegressionWithLBFGS\n",
        "\n",
        "LR_Model = LogisticRegressionWithLBFGS \\\n",
        "    .train(births_train, iterations=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH1NxC-zGtab",
        "colab_type": "text"
      },
      "source": [
        "Let's now use the model to predict the classes for our testing set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "kIjPYZGCGtac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR_results = (\n",
        "        births_test.map(lambda row: row.label) \\\n",
        "        .zip(LR_Model \\\n",
        "             .predict(births_test\\\n",
        "                      .map(lambda row: row.features)))\n",
        "    ).map(lambda row: (row[0], row[1] * 1.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE848EdpGtae",
        "colab_type": "text"
      },
      "source": [
        "Let's check how well or how bad our model performed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "qAWsBJdSGtaf",
        "colab_type": "code",
        "outputId": "cab09df7-8003-45a3-90a1-701c38fe9d40",
        "colab": {}
      },
      "source": [
        "import pyspark.mllib.evaluation as ev\n",
        "LR_evaluation = ev.BinaryClassificationMetrics(LR_results)\n",
        "\n",
        "print('Area under PR: {0:.2f}' \\\n",
        "      .format(LR_evaluation.areaUnderPR))\n",
        "print('Area under ROC: {0:.2f}' \\\n",
        "      .format(LR_evaluation.areaUnderROC))\n",
        "LR_evaluation.unpersist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Area under PR: 0.85\n",
            "Area under ROC: 0.63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYyW6zzrGtah",
        "colab_type": "text"
      },
      "source": [
        "### Selecting only the most predictable features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le0ZUOkyGtai",
        "colab_type": "text"
      },
      "source": [
        "MLLib allows us to select the most predictable features using a Chi-Square selector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "zHD-poUQGtai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "selector = ft.ChiSqSelector(4).fit(births_train)\n",
        "\n",
        "topFeatures_train = (\n",
        "        births_train.map(lambda row: row.label) \\\n",
        "        .zip(selector \\\n",
        "             .transform(births_train \\\n",
        "                        .map(lambda row: row.features)))\n",
        "    ).map(lambda row: reg.LabeledPoint(row[0], row[1]))\n",
        "\n",
        "topFeatures_test = (\n",
        "        births_test.map(lambda row: row.label) \\\n",
        "        .zip(selector \\\n",
        "             .transform(births_test \\\n",
        "                        .map(lambda row: row.features)))\n",
        "    ).map(lambda row: reg.LabeledPoint(row[0], row[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DinqTy0OGtak",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest in Spark\n",
        "\n",
        "We are now ready to build the random forest model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "aoIMH1upGtal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.mllib.tree import RandomForest\n",
        "\n",
        "RF_model = RandomForest \\\n",
        "    .trainClassifier(data=topFeatures_train, \n",
        "                     numClasses=2, \n",
        "                     categoricalFeaturesInfo={}, \n",
        "                     numTrees=6,  \n",
        "                     featureSubsetStrategy='all',\n",
        "                     seed=666)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35Y_BhmDGtan",
        "colab_type": "text"
      },
      "source": [
        "Let's see how well our model did."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "wm14Gd2HGtao",
        "colab_type": "code",
        "outputId": "27df34a3-a19c-4655-c6cc-07f3809652b3",
        "colab": {}
      },
      "source": [
        "RF_results = (\n",
        "        topFeatures_test.map(lambda row: row.label) \\\n",
        "        .zip(RF_model \\\n",
        "             .predict(topFeatures_test \\\n",
        "                      .map(lambda row: row.features)))\n",
        "    )\n",
        "\n",
        "RF_evaluation = ev.BinaryClassificationMetrics(RF_results)\n",
        "\n",
        "print('Area under PR: {0:.2f}' \\\n",
        "      .format(RF_evaluation.areaUnderPR))\n",
        "print('Area under ROC: {0:.2f}' \\\n",
        "      .format(RF_evaluation.areaUnderROC))\n",
        "RF_evaluation.unpersist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Area under PR: 0.86\n",
            "Area under ROC: 0.63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ClY-WCYGtaq",
        "colab_type": "text"
      },
      "source": [
        "Let's see how the logistic regression would perform with reduced number of features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "6QP6waO-Gtaq",
        "colab_type": "code",
        "outputId": "6da22ab2-6ee1-4967-fdda-6845c0585686",
        "colab": {}
      },
      "source": [
        "LR_Model_2 = LogisticRegressionWithLBFGS \\\n",
        "    .train(topFeatures_train, iterations=10)\n",
        "\n",
        "LR_results_2 = (\n",
        "        topFeatures_test.map(lambda row: row.label) \\\n",
        "        .zip(LR_Model_2 \\\n",
        "             .predict(topFeatures_test \\\n",
        "                      .map(lambda row: row.features)))\n",
        "    ).map(lambda row: (row[0], row[1] * 1.0))\n",
        "\n",
        "LR_evaluation_2 = ev.BinaryClassificationMetrics(LR_results_2)\n",
        "\n",
        "print('Area under PR: {0:.2f}' \\\n",
        "      .format(LR_evaluation_2.areaUnderPR))\n",
        "print('Area under ROC: {0:.2f}' \\\n",
        "      .format(LR_evaluation_2.areaUnderROC))\n",
        "LR_evaluation_2.unpersist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Area under PR: 0.85\n",
            "Area under ROC: 0.63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GRk8n0fcljq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pyspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faU5S_SJco7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}